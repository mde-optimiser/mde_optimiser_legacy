\section{Related Work}
\label{section:related_work}

	\begin{draftlist}
		To discuss:
		\item MOMOT \cite{Fleck15}
		\item QVTR \cite{Drago+10,Drago+11,Drago+15}
		\item Crepe \cite{Efstathiou+14b,Williams13}
		\item Searching Models, Modeling Search: On the Synergies of SBSE and MDE \cite{Kessentini+13}. General position paper. Focuses on genetic encoding of models 
		      (like Crepe). Proposes a general infrastructure/architecture for MDE search.
		\item \cite{Denil+14} (also a version at https://www.cs.mcgill.ca/files/techReports/icse.pdf) use transformation scheduling specifications to implement 
		      single-state (non-population based) optimisation algorithms directly over models 
		      (using transformations to describe exploration steps). They provide some good arguments for why this is a good approach. I think their approach would be
					difficult to extend to population-based approaches as the current model is somewhat implicit in the scheduling specification. Also, they do not touch on
					what breeding means for models. They provide some performance analysis.
					
					%Look at references in \cite{Denil+14}!
					
		\item \cite{Abdeen+14} present an approach similar to MOMOT, but based on Viatra. Have some interesting discussion of repair/ranking of invalid solution
		      candidates.
					
	  \item \cite{BurtonPoulding13} gives a good discussion of why one would want to optimise at the model level. They also introduce the idea of domain-specific
		      encodings (even though they don't call it that). In \cite{Burton+12} they give a concrete application example (resource allocation) and present an 
					Epsilon-based tool doing the optimisation. An interesting effect here is that they are specifically identifying only a part of the model that the optimiser
					actually manipulates (correspondences between model elements in a requirements and an implementations model). This allows crossover to be expressed
					relatively easily, but comes at the cost of having to run a transformation for every fitness evaluation to reconstruct the ``phenotype'' model.
	\end{draftlist}

  Existing approaches to search and optimisation in MDE can be grouped into three categories:
	\draft{I'm not currently including approaches that didn't try to be generic but applied SBSE ideas to specific problems}
	\begin{enumerate}
		\item Genome encodings of models; 
		\item Genome encodings of transformation sequences; and
		\item Direct search on models.
	\end{enumerate}
	\draft{QVTR doesn't fit into this. Probably need an `other' category} We'll briefly introduce each of these types of approaches.
	
	\subsection{Genome encodings of models}
	
	  \begin{draftlist}
		  To discuss:
  		\item Crepe \cite{Efstathiou+14b,Williams13}
	  	\item Searching Models, Modeling Search: On the Synergies of SBSE and MDE \cite{Kessentini+13}. General position paper. Focuses on genetic encoding of models 
		        (like Crepe). Proposes a general infrastructure/architecture for MDE search.
  	\end{draftlist}
	
	\subsection{Genome encodings of transformation sequences}

		\begin{draftlist}
			To discuss:
			\item MOMOT \cite{Fleck15}					
			\item \cite{Abdeen+14} present an approach similar to MOMOT, but based on Viatra. Have some interesting discussion of repair/ranking of invalid solution
						candidates.
		\end{draftlist}

	\subsection{Direct search on models}
	
		\begin{draftlist}
			To discuss:
			\item \cite{Denil+14} (also a version at https://www.cs.mcgill.ca/files/techReports/icse.pdf) use transformation scheduling specifications to implement 
						single-state (non-population based) optimisation algorithms directly over models 
						(using transformations to describe exploration steps). They provide some good arguments for why this is a good approach. I think their approach would be
						difficult to extend to population-based approaches as the current model is somewhat implicit in the scheduling specification. Also, they do not touch on
						what breeding means for models. They provide some performance analysis.
						
			\item \cite{BurtonPoulding13} gives a good discussion of why one would want to optimise at the model level. They also introduce the idea of domain-specific
						encodings (even though they don't call it that). In \cite{Burton+12} they give a concrete application example (resource allocation) and present an 
						Epsilon-based tool doing the optimisation. An interesting effect here is that they are specifically identifying only a part of the model that the 
						optimiser actually manipulates (correspondences between model elements in a requirements and an implementations model). This allows crossover to be
						expressed relatively easily, but comes at the cost of having to run a transformation for every fitness evaluation to reconstruct the ``phenotype'' model.
		\end{draftlist}